snippet     spark_read_from_textfile
abbr        sc.textFile()
options     word
	${1:spark_context}.textFile(${2:path_to_file}${3:, minPartitions=None}${4:, use_unicode=True})

snippet     spark_session_read_json_as_df
abbr        spark.read.json()
options     word
	${3:df} = ${1:spark_session}.read.json(${2:path_to_file})${0}

snippet     spark_session_with_config
abbr        
options     word
	${2:spark_session} = pyspark.sql.SparkSession.builder.config(conf=${1:spark_conf}).getOrCreate()

snippet     spark_session_sql
abbr        
options     word
	${3:df} = ${1:spark_session}.sql("${2:sql}")${0}

snippet     spark_df_describe_all
abbr        spark_df_describe
options     word
	${1:df}.describe().show()${0}

snippet     spark_df_to_csv
abbr        spark df to csv
options     head
    ${1:df}.write.format('com.databricks.spark.csv').save('${2:path_to_csv}')${0}

snippet     spark_df_to_csv_with_mode
abbr        spark df to csv with mode
options     head
    ${1:df}.write.format(
        "com.databricks.spark.csv"
    ).mode(
        "${2:overwrite}"
    ).save("${3:path_to_csv}")${0}

snippet     spark_df_to_csv_with_header
abbr        spark df to csv with mode
options     head
    ${1:df}.write.format(
        "com.databricks.spark.csv"
    ).mode(
        "${2:overwrite}"
    ).save("${3:path_to_csv}", header=True)${0}

snippet     spark_df_column_list
abbr        spark df column list
options     word
    ${1:df}.schema.names

snippet     spark_configure_local
abbr        pyspark.SparkConf
options     word
    ${4:conf} = ${1:pyspark.}SparkConf(
    ).setMaster(
        "${2:local}"
    ).setAppName(
        "${3:name_of_app}"
    )${0}

snippet     spark_make_spark_context
abbr        pyspark.SparkContext
options     word
    ${2:spark_context} = pyspark.SparkContext(${1:conf=conf})

