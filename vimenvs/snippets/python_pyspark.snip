include python_pyspark_context.snip
include python_pyspark_dataframe.snip
include python_pyspark_rdd.snip
include python_pyspark_spark_session.snip

#
# import
#
snippet     spark_import
abbr        import
options     word
	import pyspark

snippet     spark_import_sql
abbr        import
options     word
	import pyspark.sql as sql

snippet     spark_import_functions
abbr        import
options     word
	import pyspark.sql.functions as functions

snippet     spark_import_types
abbr        import
options     word
	import pyspark.sql.types as types

snippet     spark_import_window
abbr        import
options     word
	import pyspark.sql.window as window

#
# create
#
snippet     spark_create_spark_config
abbr        pyspark.sparkconf
options     word
	${4:conf} = pyspark.SparkConf(
	).setMaster(
		"${2:local}"
	).setAppName(
		"${3:name_of_app}"
	)${0}

#
# template
#
snippet     spark_template_logger
abbr        logger
options     word
	def get_logger(sc, name):
		"""get_logger
	
		:param name:
	
		Example
		========
	
		>>> logger = get_logger(sc, __name__)
		>>> logger.info("pyspark script logger initialized")
		"""
		log4j = sc._jvm.org.apache.log4j
		return log4j.LogManager.getLogger(name)
